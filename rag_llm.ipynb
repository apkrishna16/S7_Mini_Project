{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishna\\AppData\\Roaming\\Python\\Python312\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and modules\n",
    "import os  \n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate  \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "import chromadb \n",
    "from chromadb.config import Settings\n",
    "import textwrap \n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for storing retriever and chunked documents\n",
    "BM25_RETRIEVER_FILE = \"bm25_retriever.pkl\"\n",
    "CHUNKED_DOCS_FILE = \"chunked_documents.pkl\"\n",
    "TXT_DIR = 'Judgement_txt'  # Directory containing judgment text files\n",
    "\n",
    "COLLECTION_NAME = \"legal_judgments\"  # ChromaDB collection name\n",
    "model_name = \"llama3.2:3b\"  # Evaluation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query_variations(query, llm_model, n=3):\n",
    "    \"\"\"\n",
    "    Generates alternative query variations for retrieving documents from a vector database.\n",
    "\n",
    "    Parameters:\n",
    "    - query: The original query string.\n",
    "    - llm_model: The language model used for generating variations.\n",
    "    - n: Number of variations to generate (default is 3).\n",
    "\n",
    "    Output:\n",
    "    - Returns a list containing the original query and its variations.\n",
    "    \"\"\"\n",
    "    \n",
    "    response_schemas = [\n",
    "        ResponseSchema(name=f\"variation_{i+1}\", description=f\"Variation {i+1} of the query\")\n",
    "        for i in range(n)\n",
    "    ] \n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    " \n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=(\n",
    "            f\"You are an AI assistant. Your task is to generate {n} alternative versions \"\n",
    "            \"of the following question to retrieve relevant documents from a vector database. \"\n",
    "            f\"Format the output strictly as JSON with fields: {', '.join([f'variation_{i+1}' for i in range(n)])}.\"\n",
    "            \"You must always return valid JSON fenced by a markdown code block. Do not return any additional text.\"\n",
    "            \"\\nOriginal question: {question}\"\n",
    "            \"\\n{format_instructions}\"\n",
    "        ),\n",
    "        partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    "    )\n",
    " \n",
    "    chain = prompt | llm_model \n",
    "    response = chain.invoke({\"question\": query})\n",
    "    parsed_response = output_parser.parse(response)\n",
    " \n",
    "    variations = [query]\n",
    "    variations.extend([\n",
    "        parsed_response[f\"variation_{i+1}\"]\n",
    "        for i in range(n)\n",
    "    ])\n",
    " \n",
    "    return variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_chromadb(collection_name):\n",
    "    \"\"\"\n",
    "    Initializes ChromaDB with persistence settings.\n",
    "\n",
    "    Parameters:\n",
    "    - collection_name: Name of the collection to initialize in ChromaDB.\n",
    "\n",
    "    Output:\n",
    "    - Returns an initialized collection from ChromaDB.\n",
    "    \"\"\"\n",
    "    \n",
    "    client = chromadb.Client(Settings(is_persistent=True, persist_directory= './chormadb'))\n",
    "    collection = client.get_or_create_collection(collection_name)\n",
    "    print(f\"ChromaDB initialized and collection '{collection_name}' ready\")\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(query, collection, top_n=5):\n",
    "    \"\"\"\n",
    "    Performs vector-based search to retrieve top `n` document chunks.\n",
    "\n",
    "    Parameters:\n",
    "    - query: The query string for which relevant documents are to be retrieved.\n",
    "    - collection: The collection from which documents are to be searched.\n",
    "    - top_n: Number of top results to retrieve (default is 5).\n",
    "\n",
    "    Output:\n",
    "    - Returns a list of dictionaries containing document details such as ID, content, parent document name, and rank.\n",
    "    \"\"\"\n",
    "\n",
    "    encoder_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "    query_embedding = encoder_model.encode(query)\n",
    "    results = collection.query(query_embeddings=[query_embedding.tolist()], n_results=top_n) \n",
    "     \n",
    "    vector_results = [\n",
    "        {\n",
    "            \"id\": doc_id,\n",
    "            \"document\": doc_content,\n",
    "            \"parent\": doc_id.split(\"_chunk_\")[0],   \n",
    "            \"rank\": rank + 1  \n",
    "        }\n",
    "        for rank, (doc_id, doc_content) in enumerate(zip(results[\"ids\"][0], results[\"documents\"][0]))\n",
    "    ] \n",
    "    return vector_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_search(query, top_n=5):\n",
    "    \"\"\"\n",
    "    Performs keyword-based search using BM25 to retrieve top `n` document chunks.\n",
    "\n",
    "    Parameters:\n",
    "    - query: The query string for which relevant documents are to be retrieved.\n",
    "    - top_n: Number of top results to retrieve (default is 5).\n",
    "\n",
    "    Output:\n",
    "    - Returns a list of dictionaries containing document details such as ID, content, parent document name, and rank.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(BM25_RETRIEVER_FILE, \"rb\") as f:\n",
    "        retriever = pickle.load(f)\n",
    "\n",
    "    with open(CHUNKED_DOCS_FILE, \"rb\") as f:\n",
    "        corpus = pickle.load(f)\n",
    "    \n",
    "    processed_query = query.split() \n",
    "    results = retriever.get_top_n(processed_query, corpus, top_n) \n",
    " \n",
    "    keyword_results = [\n",
    "        {\n",
    "            \"id\": f'{result.metadata.get(\"source\", \"unknown\")}_doc_{i}',\n",
    "            \"document\": result.page_content,\n",
    "            \"parent\": result.metadata.get(\"source\", \"unknown\"),   \n",
    "            \"rank\": i + 1  \n",
    "        }\n",
    "        for i, result in enumerate(results)\n",
    "    ] \n",
    "    \n",
    "    return keyword_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_reranking(vector_results, keyword_results, k=60):\n",
    "    \"\"\"\n",
    "    Reranks results from vector and keyword search using Reciprocal Rank Fusion (RRF) \n",
    "    and merges fused scores by parent document.\n",
    "\n",
    "    Parameters:\n",
    "    - vector_results: List of results from vector-based search.\n",
    "    - keyword_results: List of results from keyword-based search.\n",
    "    - k: Hyperparameter for RRF to adjust the influence of rank (default is 60).\n",
    "\n",
    "    Output:\n",
    "    - Returns a reranked list of parent documents with their combined scores and associated chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    fused_scores = {}\n",
    "    parent_scores = {}\n",
    "    parent_documents = {}\n",
    " \n",
    "    for result_list in vector_results:   \n",
    "        for result in result_list:   \n",
    "            doc_id = result[\"id\"]\n",
    "            parent = result[\"parent\"]\n",
    "            if parent not in parent_documents:\n",
    "                parent_documents[parent] = []\n",
    "            parent_documents[parent].append(result[\"document\"])\n",
    "\n",
    "            fused_scores[doc_id] = fused_scores.get(doc_id, 0) + 1 / (result[\"rank\"] + k)\n",
    " \n",
    "    for result_list in keyword_results:   \n",
    "        for result in result_list:   \n",
    "            doc_id = result[\"id\"]\n",
    "            parent = result[\"parent\"]\n",
    "            if parent not in parent_documents:\n",
    "                parent_documents[parent] = []\n",
    "            parent_documents[parent].append(result[\"document\"])\n",
    "\n",
    "            fused_scores[doc_id] = fused_scores.get(doc_id, 0) + 1 / (result[\"rank\"] + k)\n",
    " \n",
    "    for doc_id, score in fused_scores.items():\n",
    "        parent = doc_id.split(\"_\")[0]  \n",
    "        parent_scores[parent] = parent_scores.get(parent, 0) + score\n",
    " \n",
    "    reranked_results = sorted(\n",
    "        [\n",
    "            {\n",
    "                \"parent\": parent,\n",
    "                \"score\": score,\n",
    "                \"documents\": parent_documents[parent]\n",
    "            }\n",
    "            for parent, score in parent_scores.items()\n",
    "        ],\n",
    "        key=lambda x: x[\"score\"], reverse=True\n",
    "    )\n",
    "    return reranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_reranked_docs(reranked_results, top_percent=None, threshold=None):\n",
    "    \"\"\"\n",
    "    Filters reranked documents based on a specified top percentage or a probability threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - reranked_results: List of reranked documents with scores.\n",
    "    - top_percent: Percentage of top documents to retain (optional, 0 < top_percent <= 100).\n",
    "    - threshold: Minimum probability threshold for including documents (optional, 0 <= threshold <= 1).\n",
    "\n",
    "    Output:\n",
    "    - Returns a filtered list of documents meeting the specified criteria.\n",
    "    \"\"\"\n",
    "\n",
    "    if not reranked_results:\n",
    "        return []\n",
    " \n",
    "    reranked_results = sorted(reranked_results, key=lambda x: x[\"score\"], reverse=True)\n",
    " \n",
    "    scores = [doc[\"score\"] for doc in reranked_results] \n",
    "    sum_scores = sum(scores)\n",
    "    probabilities = [score / sum_scores for score in scores]\n",
    "     \n",
    "    print(\"\\nDocuments and Scores\")\n",
    "    for doc, prob in zip(reranked_results, probabilities):\n",
    "        doc[\"probability\"] = prob\n",
    "        print(f'{doc[\"parent\"]} - {doc[\"score\"]:.4f}, {doc[\"probability\"]:.4f}')\n",
    "         \n",
    "    if top_percent:\n",
    "        cutoff_index = int(len(reranked_results) * (top_percent / 100))\n",
    "        filtered_docs = reranked_results[:cutoff_index+1]\n",
    "    else:\n",
    "        filtered_docs = reranked_results\n",
    " \n",
    "    if threshold:\n",
    "        filtered_docs = [doc for doc in filtered_docs if doc[\"probability\"] >= threshold]\n",
    " \n",
    "    if filtered_docs:\n",
    "        last_prob = filtered_docs[-1][\"probability\"]\n",
    "        filtered_docs.extend(\n",
    "            doc for doc in reranked_results[len(filtered_docs):] if doc[\"probability\"] == last_prob\n",
    "        )\n",
    "\n",
    "    if filtered_docs == []:\n",
    "        filtered_docs = [reranked_results[0]]\n",
    "\n",
    "    return filtered_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_parent_document(parent_doc_id):\n",
    "    \"\"\"\n",
    "    Retrieves the content of a parent document from a specified directory.\n",
    "\n",
    "    Parameters:\n",
    "    - parent_doc_id: The name of the parent document to retrieve.\n",
    "\n",
    "    Output:\n",
    "    - Returns the content of the document as a string if found.\n",
    "    - Returns None if the document is not found.\n",
    "\n",
    "    Raises:\n",
    "    - FileNotFoundError: If the file is not found in the specified directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    file_path = os.path.join(TXT_DIR, parent_doc_id)\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file {parent_doc_id} was not found in the directory {TXT_DIR}.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_text(text, width = 100): \n",
    "    \"\"\"\n",
    "    Wraps text to fit within a specified line width.\n",
    "\n",
    "    Parameters:\n",
    "    - text: The input text to be wrapped.\n",
    "    - width: The maximum width of each line (default is 100 characters).\n",
    "\n",
    "    Output:\n",
    "    - Returns the wrapped text where each line does not exceed the specified width.\n",
    "    \"\"\"\n",
    "    \n",
    "    lines = text.split('\\n') \n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines] \n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_responses_with_reranking(user_query, model_name, prompt_template, k, top_n=10, top_percent=None, threshold=None):\n",
    "    \"\"\"\n",
    "    Generates responses for filtered and reranked parent documents using an LLM.\n",
    "\n",
    "    Parameters:\n",
    "    - user_query (str): The query to retrieve documents.\n",
    "    - model_name (str): The name of the LLM model to generate responses.\n",
    "    - prompt_template (str): Template for prompt generation.\n",
    "    - k (int): Number of query variations to generate.\n",
    "    - top_n (int): Number of top results to retrieve from each search.\n",
    "    - top_percent (float): Percentage of top documents to keep (0 < top_percent <= 100).\n",
    "    - threshold (float): Minimum probability to include a document (0 <= threshold <= 1).\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary mapping parent documents to their LLM-generated responses.\n",
    "    \"\"\"\n",
    "\n",
    "    collection = init_chromadb(COLLECTION_NAME)\n",
    "    ollama_model = OllamaLLM(model=model_name)\n",
    "\n",
    "    print(f\"User Query \\n{user_query}\")\n",
    "\n",
    "    queries = generate_query_variations(user_query, ollama_model, k)     \n",
    "\n",
    "    vector_results = []\n",
    "    keyword_results = []\n",
    "\n",
    "    print(\"\\nRetrieved Documents\")\n",
    "    for i, query in enumerate(queries):\n",
    "        print(f\"Query - '{query}'\")\n",
    "        vector_result = vector_search(query, collection, top_n)\n",
    "        vector_ids = ' | '.join(item[\"id\"] for item in vector_result if \"id\" in item) if vector_result else \"No results\"\n",
    "        print(f\"Vector search results - {vector_ids}\")\n",
    "        vector_results.append(vector_result) \n",
    "        keyword_result = keyword_search(query, top_n)\n",
    "        keyword_ids = ' | '.join(item[\"id\"] for item in keyword_result if \"id\" in item) if keyword_result else \"No results\"\n",
    "        print(f\"Keyword search results - {keyword_ids}\")\n",
    "        keyword_results.append(keyword_result)\n",
    " \n",
    "    reranked_results = reciprocal_reranking(vector_results, keyword_results)  \n",
    "          \n",
    "    filtered_docs = filter_reranked_docs(reranked_results, top_percent=top_percent, threshold=threshold) \n",
    "    print(\"\\nFiltered Document\")\n",
    "    for doc in filtered_docs:\n",
    "        parent_doc_id = doc[\"parent\"]\n",
    "        probability = doc.get(\"probability\", 0.0)\n",
    "        print(parent_doc_id, ' - ', probability)\n",
    " \n",
    "    responses = {}\n",
    "\n",
    "    for doc in filtered_docs:\n",
    "        parent_doc_id = doc[\"parent\"] \n",
    "        probability = doc.get(\"probability\", 0.0) \n",
    "        context = retrieve_parent_document(parent_doc_id)\n",
    "\n",
    "        if context:\n",
    "            print(\"File content loaded successfully!\")\n",
    "        else:\n",
    "            print(\"File could not be loaded.\") \n",
    "\n",
    "       \n",
    "        print(f\"\\nGenerating response for parent document: {parent_doc_id} (Probability: {probability:.4f})\")\n",
    "\n",
    "        prompt = PromptTemplate(input_variables=[\"query\", \"context\"], template=prompt_template)  \n",
    "        chain = prompt | ollama_model\n",
    "        response = chain.invoke({\"query\":user_query, \"context\":context}) \n",
    "        responses[parent_doc_id] = response \n",
    "        \n",
    "        print(wrap_text(response), sep='\\n')\n",
    "\n",
    "    return responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Given the following context related to Indian legal judgments:\n",
    "'{context}'\n",
    "\n",
    "Please perform the following tasks:\n",
    "1. Answer the question: '{query}' based on the provided context.\n",
    "2. Identify and list all acts, laws, rules, statutes, and legal provisions explicitly mentioned in the context.\n",
    "Provide a clear and concise response for each task.\n",
    "\"\"\"\n",
    "no_of_queries = 3\n",
    "no_of_docs = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the main constitutional challenge presented in the petition under Article 32 of the Indian Constitution regarding the U.P. Land Tenures (Regulation of Transfers) Act 1952 and the Indian Forest (U.P. Amendment) Act 1956?\"\n",
    "response = generate_responses_with_reranking(query, model_name, prompt_template, no_of_queries, no_of_docs, top_percent=None, threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB initialized and collection 'legal_judgments' ready\n",
      "User Query \n",
      "Can an appeal be filed against the levy of penal interest under Section 18A of the Indian Income-tax Act, 1922?\n",
      "\n",
      "Retrieved Documents\n",
      "Query - 'Can an appeal be filed against the levy of penal interest under Section 18A of the Indian Income-tax Act, 1922?'\n",
      "Vector search results - 0000002833.txt_chunk_1 | 0001338548.txt_chunk_5 | 0000002833.txt_chunk_4 | 0000002833.txt_chunk_9 | 0001880845.txt_chunk_1\n",
      "Keyword search results - 0000002833.txt_doc_0 | 0000020346.txt_doc_1 | 0000002833.txt_doc_2 | 0000002833.txt_doc_3 | 0000002833.txt_doc_4\n",
      "Query - 'Can an appeal be filed against the levy of penal interest under section 18A of the Indian Income-tax Act, 1922?'\n",
      "Vector search results - 0000002833.txt_chunk_1 | 0001338548.txt_chunk_5 | 0000002833.txt_chunk_4 | 0000002833.txt_chunk_9 | 0001880845.txt_chunk_1\n",
      "Keyword search results - 0000002833.txt_doc_0 | 0000002833.txt_doc_1 | 0000020346.txt_doc_2 | 0000002833.txt_doc_3 | 0000002833.txt_doc_4\n",
      "Query - 'Appeal against penal interest under Section 18A of the Indian Income-tax Act, 1922 is possible?'\n",
      "Vector search results - 0000002833.txt_chunk_1 | 0001338548.txt_chunk_5 | 0000002833.txt_chunk_9 | 0000002833.txt_chunk_4 | 0000065501.txt_chunk_4\n",
      "Keyword search results - 0000002833.txt_doc_0 | 0000002833.txt_doc_1 | 0000002833.txt_doc_2 | 0000002833.txt_doc_3 | 0000002833.txt_doc_4\n",
      "Query - 'Is it possible to file an appeal against the imposition of penal interest under section 18A of the Indian Income-tax Act, 1922?'\n",
      "Vector search results - 0000002833.txt_chunk_1 | 0001338548.txt_chunk_5 | 0000002833.txt_chunk_9 | 0000002833.txt_chunk_4 | 0000065501.txt_chunk_4\n",
      "Keyword search results - 0000002833.txt_doc_0 | 0000002833.txt_doc_1 | 0000002833.txt_doc_2 | 0000002833.txt_doc_3 | 0000002833.txt_doc_4\n",
      "\n",
      "Documents and Scores\n",
      "0000002833.txt - 0.4772, 0.7512\n",
      "0001338548.txt - 0.0645, 0.1016\n",
      "0000020346.txt - 0.0320, 0.0504\n",
      "0001880845.txt - 0.0308, 0.0484\n",
      "0000065501.txt - 0.0308, 0.0484\n",
      "\n",
      "Filtered Document\n",
      "0000002833.txt  -  0.7511862800960455\n",
      "File content loaded successfully!\n",
      "\n",
      "Generating response for parent document: 0000002833.txt (Probability: 0.7512)\n",
      "**Task 1: Answering the question**\n",
      "\n",
      "Based on the provided context, the answer is: No, an appeal cannot be filed against the levy of\n",
      "penal interest under Section 18A of the Indian Income-tax Act, 1922. According to the judgment of\n",
      "the Supreme Court cited in the context, if the assessee denies its liability to pay such interest\n",
      "\"on the ground that he was not liable to pay advance tax at all or that the amount of advance tax\n",
      "determined as payable by the Income-tax Officer is not correct\", then an appeal to the Appellate\n",
      "Assistant Commissioner is competent. However, if the assessee only raises a contention that the\n",
      "interest charged is excessive or should be reduced, but does not deny its liability to pay such\n",
      "interest altogether, then no appeal lies.\n",
      "\n",
      "**Task 2: Listing all acts, laws, rules, statutes, and legal provisions**\n",
      "\n",
      "Here are the explicitly mentioned acts, laws, rules, statutes, and legal provisions:\n",
      "\n",
      "1. Indian Income-tax Act, 1922\n",
      "2. Section 18A of the Indian Income-tax Act, 1922\n",
      "3. Section 139 of the Indian Income-tax Act, 1961 (not explicitly mentioned in this context, but\n",
      "implied as part of the reference to Section 139)\n",
      "4. Rule 117A of the Income-tax Rules, 1962\n",
      "5. Rule 40 of the Income-tax Rules, 1962\n",
      "\n",
      "Note that the judgment also references several other cases and statutes (e.g., Section 216, Clause\n",
      "(c) of Section 246), but these are not explicitly mentioned as part of the specific legal provisions\n",
      "at issue in this context.\n"
     ]
    }
   ],
   "source": [
    "query = \"Can an appeal be filed against the levy of penal interest under Section 18A of the Indian Income-tax Act, 1922?\"\n",
    "response = generate_responses_with_reranking(query, model_name, prompt_template, no_of_queries, no_of_docs, top_percent=None, threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB initialized and collection 'legal_judgments' ready\n",
      "User Query \n",
      "Does the improper joinder of a non-contesting candidate invalidate an election petition under the Representation of the People Act, 1951?\n",
      "\n",
      "Retrieved Documents\n",
      "Query - 'Does the improper joinder of a non-contesting candidate invalidate an election petition under the Representation of the People Act, 1951?'\n",
      "Vector search results - 0001694314.txt_chunk_1 | 0001962951.txt_chunk_23 | 0001742283.txt_chunk_13 | 0000264503.txt_chunk_2 | 0000000599.txt_chunk_7\n",
      "Keyword search results - 0000757046.txt_doc_0 | 0001504198.txt_doc_1 | 0000010498.txt_doc_2 | 0001013291.txt_doc_3 | 0000663763.txt_doc_4\n",
      "Query - 'Is improper joinder of a non-contesting candidate a valid reason to invalidate an election petition under the Representation of the People Act, 1951?'\n",
      "Vector search results - 0000000599.txt_chunk_7 | 0001742283.txt_chunk_13 | 0001694314.txt_chunk_1 | 0001962951.txt_chunk_23 | 0001504198.txt_chunk_28\n",
      "Keyword search results - 0000663763.txt_doc_0 | 0001504198.txt_doc_1 | 0001612935.txt_doc_2 | 0000010498.txt_doc_3 | 0000757046.txt_doc_4\n",
      "Query - 'Does the improper inclusion of a non-contesting candidate in an election petition constitute grounds for invalidation under the Representation of the People Act, 1951?'\n",
      "Vector search results - 0001962951.txt_chunk_23 | 0001694314.txt_chunk_1 | 0001742283.txt_chunk_13 | 0000264503.txt_chunk_2 | 0001504198.txt_chunk_3\n",
      "Keyword search results - 0000757046.txt_doc_0 | 0001504198.txt_doc_1 | 0001905805.txt_doc_2 | 0001612935.txt_doc_3 | 0001013291.txt_doc_4\n",
      "Query - 'Is it valid to reject an election petition if a non-contesting candidate is improperly joined, as per the Representation of the People Act, 1951?'\n",
      "Vector search results - 0001694314.txt_chunk_1 | 0001962951.txt_chunk_23 | 0001742283.txt_chunk_13 | 0000000599.txt_chunk_7 | 0000016726.txt_chunk_3\n",
      "Keyword search results - 0000663763.txt_doc_0 | 0000000599.txt_doc_1 | 0000757046.txt_doc_2 | 0000010498.txt_doc_3 | 0000663763.txt_doc_4\n",
      "\n",
      "Documents and Scores\n",
      "0001504198.txt - 0.0792, 0.1246\n",
      "0001694314.txt - 0.0648, 0.1020\n",
      "0001962951.txt - 0.0643, 0.1012\n",
      "0000757046.txt - 0.0640, 0.1008\n",
      "0001742283.txt - 0.0637, 0.1004\n",
      "0000663763.txt - 0.0636, 0.1001\n",
      "0000000599.txt - 0.0635, 0.1000\n",
      "0000010498.txt - 0.0471, 0.0742\n",
      "0001612935.txt - 0.0315, 0.0496\n",
      "0000264503.txt - 0.0312, 0.0492\n",
      "0001013291.txt - 0.0310, 0.0488\n",
      "0001905805.txt - 0.0159, 0.0250\n",
      "0000016726.txt - 0.0154, 0.0242\n",
      "\n",
      "Filtered Document\n",
      "0001504198.txt  -  0.12460837122554201\n",
      "File content loaded successfully!\n",
      "\n",
      "Generating response for parent document: 0001504198.txt (Probability: 0.1246)\n",
      "**Task 1: Answering the question**\n",
      "\n",
      "Based on the provided context, it appears that the court has ruled that improper joinder of a non-\n",
      "contesting candidate does not invalidate an election petition under the Representation of the People\n",
      "Act, 1951. The court has found that while the petitioner has failed to establish that the result of\n",
      "the election was materially affected by Mr. <NAME>'s false statements, it does not necessarily mean\n",
      "that the improper joinder is a valid reason for invalidating the election petition.\n",
      "\n",
      "The court seems to imply that the burden of proof lies with the petitioner to establish the impact\n",
      "of the false statements on the election outcome, and that simply because a non-contesting candidate\n",
      "is included in the election, it may not be sufficient grounds to invalidate the entire process.\n",
      "Therefore, the answer to the question is likely \"no\", improper joinder of a non-contesting candidate\n",
      "does not invalidate an election petition under the Representation of the People Act, 1951.\n",
      "\n",
      "**Task 2: Listing explicit acts, laws, rules, statutes, and legal provisions**\n",
      "\n",
      "Here are the explicitly mentioned acts, laws, rules, statutes, and legal provisions:\n",
      "\n",
      "1. The Representation of the People Act, 1951\n",
      "2. Election Law (not specifically specified, but referenced as \"election law\" in certain contexts)\n",
      "3. Laws of Vashist's case ([CITATION] (1))\n",
      "4. Rulings of the Organization ([CITATION] (2) and [CITATION] (3))\n",
      "5. The English ruling cited to the court (not explicitly specified, but mentioned as a comparative\n",
      "example)\n",
      "\n",
      "Please note that some references ([CITATION]) are not provided in the context, so I could not\n",
      "include them in the list.\n"
     ]
    }
   ],
   "source": [
    "query = \"Does the improper joinder of a non-contesting candidate invalidate an election petition under the Representation of the People Act, 1951?\"\n",
    "response = generate_responses_with_reranking(query, model_name, prompt_template, no_of_queries, no_of_docs, top_percent=None, threshold=0.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
